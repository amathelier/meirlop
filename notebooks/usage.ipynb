{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Usage"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dependencies\n",
    "This project depends on working installations of:\n",
    "* Biopython\n",
    "* joblib\n",
    "* MOODS\n",
    "* numpy\n",
    "* pandas\n",
    "* pybedtools\n",
    "* scikit-learn\n",
    "* statsmodels\n",
    "* tqdm\n",
    "\n",
    "All dependencies are available via conda.\n",
    "\n",
    "This notebook additionally depends on:\n",
    "* wget\n",
    "* zcat\n",
    "\n",
    "### MOODS Motif scanning\n",
    "Motif scanning functionality depends on the [MOODS Python module](https://github.com/jhkorhonen/MOODS/tree/master/python), which is available via [conda](https://anaconda.org/bioconda/moods). This may have to be installed manually if you don't use conda, since there is currently no PyPi package.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import datetime\n",
    "from timeit import default_timer as timer\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generate scored and stratified fasta file from peak data\n",
    "For each peak, output should appear as:\n",
    "```\n",
    ">sequence_name score stratum other_descriptive_text\n",
    "SEQUENCESEQUENCESEQUENCE\n",
    "```\n",
    "\n",
    "In this example, we set `score` to `log2fc * (1-pval)` using values from our peak file.  \n",
    "The strata are derived from the GC% content of the sequence, rounded to the nearest 5%.  \n",
    "If strata are unimportant, you may simply enter a single constant.  \n",
    "If you already have such a file, skip to **Load data for motif enrichment**  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Download and locate reference sequence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "if [ ! -f genome.fa ]; then\n",
    "    wget \\\n",
    "    ftp://ftp.ebi.ac.uk/pub/databases/gencode/Gencode_human/release_28/GRCh38.primary_assembly.genome.fa.gz \\\n",
    "    -O genome.fa.gz\n",
    "    zcat genome.fa.gz > genome.fa\n",
    "fi\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "genome_fa_filename = f'genome.fa'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Locate peak data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "peaks_filename = 'differential_peaks.txt'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "peaks_df = pd.read_table(peaks_filename)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Annotate peaks with additional information"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "min_tag_limit = 10\n",
    "\n",
    "peak_annotation_columns = ['chr', 'start', 'end', 'strand', 'log2fc', 'pval', 'min_tags']\n",
    "peak_id_column = 'PeakID'\n",
    "\n",
    "peak_annotation_df = (peaks_df[peaks_df['min_tags'] >= min_tag_limit]\n",
    "                      .rename(columns = {peak_id_column: 'peak_id'})\n",
    "                      [list(set(['peak_id'] + peak_annotation_columns))]\n",
    "                      .rename(columns = {col: f'peak_{col}' \n",
    "                                         for col \n",
    "                                         in peak_annotation_columns})\n",
    "                      .drop_duplicates())\n",
    "\n",
    "peak_annotation_df = peak_annotation_df[['peak_id'] + [f'peak_{col}' for col in peak_annotation_columns]]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Weight log2fc by 1-pval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "peak_annotation_df['peak_weighted_log2fc'] = peak_annotation_df['peak_log2fc'] * (1 - peak_annotation_df['peak_pval'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Set score for each peak equal to the weighted log2fc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "peak_annotation_df['peak_score'] = peak_annotation_df['peak_weighted_log2fc']\n",
    "peak_annotation_bed_columns = ['peak_chr', 'peak_start', 'peak_end', 'peak_id', 'peak_score', 'peak_strand']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "peak_annotation_df[peak_annotation_bed_columns].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Extract peak sequence +/- 300 from peak center"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sequence_length = 600"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "peak_annotation_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "peak_annotation_bed_columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Write fasta file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from meirlop import get_centered_peak_sequences, get_gc_pct, get_gc_pct_bin, write_scored_fasta\n",
    "peak_fasta_filename = 'peak_scores.fa'\n",
    "peak_fasta_file = open(peak_fasta_filename, 'w')\n",
    "\n",
    "peak_sequence_dict, peak_sequence_bed_df = get_centered_peak_sequences(peak_annotation_df, \n",
    "                                                                       genome_fa_file = open(genome_fa_filename, 'r'), \n",
    "                                                                       sequence_length = sequence_length, \n",
    "                                                                       peak_bed_columns = peak_annotation_bed_columns)\n",
    "peak_score_dict = peak_annotation_df.set_index('peak_id')['peak_score'].to_dict()\n",
    "\n",
    "peak_gc_pct_dict = {peak_id: get_gc_pct(seq) \n",
    "                        for peak_id, seq \n",
    "                        in peak_sequence_dict.items()}\n",
    "\n",
    "peak_gc_pct_bin_dict = {peak_id: get_gc_pct_bin(seq) \n",
    "                        for peak_id, seq \n",
    "                        in peak_sequence_dict.items()}\n",
    "\n",
    "peak_fasta_string = write_scored_fasta(peak_sequence_dict, \n",
    "                                       peak_score_dict, \n",
    "                                       peak_fasta_file, \n",
    "                                       other_dicts = [peak_gc_pct_bin_dict])\n",
    "peak_fasta_file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "! head {peak_fasta_filename}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "toc-hr-collapsed": false
   },
   "source": [
    "## Load data for motif enrichment"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load the scored fasta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from meirlop import read_scored_fasta, dict_to_df\n",
    "sequence_dict, score_dict, description_dict = read_scored_fasta(open(peak_fasta_filename, 'r'), description_delim = ' ')\n",
    "strata_dict = {key: int(val[2]) for key, val in description_dict.items()}\n",
    "\n",
    "score_df = dict_to_df(score_dict, 'peak_id', 'peak_score')\n",
    "strata_df = dict_to_df(strata_dict, 'peak_id', 'peak_strata')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(score_df.shape)\n",
    "score_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(strata_df.shape)\n",
    "strata_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Download and Load motif matrices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "if [ ! -f JASPAR2018_CORE_vertebrates_non-redundant_pfms_jaspar.txt ]; then\n",
    "    wget \\\n",
    "    --user-agent=\"Mozilla/5.0 (X11; Fedora; Linux x86_64; rv:52.0) Gecko/20100101 Firefox/52.0\" \\\n",
    "    http://jaspar.genereg.net/download/CORE/JASPAR2018_CORE_vertebrates_non-redundant_pfms_jaspar.txt \\\n",
    "    -O JASPAR2018_CORE_vertebrates_non-redundant_pfms_jaspar.txt\n",
    "fi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from meirlop import read_motif_matrices\n",
    "known_motifs_filename = 'JASPAR2018_CORE_vertebrates_non-redundant_pfms_jaspar.txt'\n",
    "known_motifs_file = open(known_motifs_filename, 'r')\n",
    "motif_matrix_dict, motif_consensus_dict = read_motif_matrices(known_motifs_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Scan for motifs\n",
    "Create a dictionary, where the key is the motif id, and the value is a list of peaks containing the motif."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "start = timer()\n",
    "print(datetime.datetime.now())\n",
    "\n",
    "from meirlop import format_scan_results, scan_motifs, get_background\n",
    "scan_results_df, motif_peak_set_dict = format_scan_results(scan_motifs(motif_matrix_dict, \n",
    "                                                                       peak_sequence_dict, \n",
    "                                                                       bg = get_background(''.join(peak_sequence_dict.values())), \n",
    "                                                                       pval = 0.01, \n",
    "                                                                       pseudocount = 0.001, \n",
    "                                                                       window_size = 7))\n",
    "\n",
    "end = timer()\n",
    "runtime = end - start\n",
    "print(f'{runtime} seconds')\n",
    "print(datetime.datetime.now())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Perform logistic regression analysis\n",
    "Control for GC% as a covariate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "covariates_df = dict_to_df(peak_gc_pct_dict, 'peak_id', 'peak_covariate')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(covariates_df.shape)\n",
    "covariates_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "start = timer()\n",
    "print(datetime.datetime.now())\n",
    "\n",
    "from meirlop import analyze_peaks_with_lr\n",
    "from tqdm import tqdm_notebook\n",
    "\n",
    "lr_results_df = analyze_peaks_with_lr(peak_score_df = score_df,\n",
    "                                      peak_set_dict = motif_peak_set_dict,\n",
    "                                      peak_covariates_df = covariates_df,\n",
    "                                      padj_method = 'fdr_bh',\n",
    "                                      min_set_size = 1,\n",
    "                                      max_set_size = np.inf,\n",
    "                                      n_jobs = 1, \n",
    "                                      progress_wrapper = tqdm_notebook)\n",
    "\n",
    "end = timer()\n",
    "runtime = end - start\n",
    "print(f'{runtime} seconds')\n",
    "print(datetime.datetime.now())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr_results_df.head(20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Perform enrichment analysis with stratified permutations\n",
    "We use an adaptation of GSEA prerank accounting for GC% (rounded to the nearest 5%) as strata in permutation testing.\n",
    "\n",
    "The argument `nshuf` refers to how many times the algorithm will shuffle around peaks with equal scores, in order to be robust to multiple valid orderings of peaks by score.  \n",
    "The argument `nperm` refers to how many permutations are made per shuffling of peaks with equal scores.  \n",
    "The total number of null permutations is then `nshuf * nperm`\n",
    "The argument `n_jobs_perm` refers to how many processes will be used to generate permutations.\n",
    "The argument `n_jobs_ind` refers to how many processes will be used to generate indicator variable matrices for enrichment calculations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "start = timer()\n",
    "print(datetime.datetime.now())\n",
    "\n",
    "from meirlop import analyze_peaks_with_prerank\n",
    "from tqdm import tqdm_notebook\n",
    "\n",
    "rs = np.random.RandomState(1234)\n",
    "\n",
    "analysis_results = analyze_peaks_with_prerank(peak_score_df = score_df, \n",
    "                                              peak_set_dict = motif_peak_set_dict, \n",
    "                                              peak_strata_df = strata_df, \n",
    "                                              min_set_size = 1, \n",
    "                                              max_set_size = np.inf, \n",
    "                                              nperm = 10, \n",
    "                                              nshuf = 100, \n",
    "                                              rs = rs, \n",
    "                                              n_jobs_perm = 20, \n",
    "                                              n_jobs_ind = 1, \n",
    "                                              progress_wrapper = tqdm_notebook)\n",
    "\n",
    "enrichment_score_results_df, shuffled_permuted_peak_data, peak_idx_to_peak_id = analysis_results\n",
    "\n",
    "end = timer()\n",
    "runtime = end - start\n",
    "print(f'{runtime} seconds')\n",
    "print(datetime.datetime.now())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "enrichment_score_results_df.head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "enrichment_score_results_df[enrichment_score_results_df['fdr_sig'] == 1].shape"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
